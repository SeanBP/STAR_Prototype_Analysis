{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Run11_list.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the range for Tstamp_us\n",
    "lower_bound = 1650 * ( 60 * 1e6)\n",
    "upper_bound = 1700 * ( 60 * 1e6)\n",
    "\n",
    "# Filter the DataFrame\n",
    "data = data[(data['Tstamp_us'] >= lower_bound) & (data['Tstamp_us'] <= upper_bound)]\n",
    "\n",
    "# Reset index if needed\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Brd  Ch  LG   HG     Tstamp_us  event_ids   xpos   ypos      zpos\n",
      "0          0   0  67  160  9.900006e+10     112751  50.01  18.37   24.0526\n",
      "1          0   1  47  196  9.900006e+10     112751  77.64  34.32   24.0526\n",
      "2          0   2  50  177  9.900006e+10     112751  22.37  34.32   24.0526\n",
      "3          0   3  33  166  9.900006e+10     112751  50.01  50.28   24.0526\n",
      "4          0   4  40  175  9.900006e+10     112751  77.64  66.23   24.0526\n",
      "...      ...  ..  ..  ...           ...        ...    ...    ...       ...\n",
      "2290555    2  59  17  100  1.019964e+11     153880  26.10 -26.36  241.2734\n",
      "2290556    2  60   0   61  1.019964e+11     153880 -73.90  74.16  268.4260\n",
      "2290557    2  61  32   61  1.019964e+11     153880 -26.10  74.16  268.4260\n",
      "2290558    2  62  24    0  1.019964e+11     153880 -73.90  26.36  268.4260\n",
      "2290559    2  63   0   24  1.019964e+11     153880 -26.10  26.36  268.4260\n",
      "\n",
      "[2290560 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG = np.array(data[\"LG\"])\n",
    "event_ids = np.array(data[\"event_ids\"])\n",
    "xpos = np.array(data[\"xpos\"])\n",
    "ypos = np.array(data[\"ypos\"])\n",
    "zpos = np.array(data[\"zpos\"])\n",
    "\n",
    "#LG = LG - 50.39\n",
    "\n",
    "mask = LG > 0\n",
    "\n",
    "LG = LG[mask]\n",
    "event_ids = event_ids[mask]\n",
    "xpos = xpos[mask]\n",
    "ypos = ypos[mask]\n",
    "zpos = zpos[mask]\n",
    "\n",
    "events = list(set(event_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spreins/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/Users/spreins/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "use_log_scale = False  # Set to True for logarithmic scale, False for linear scale\n",
    "time_window = 1 # All hits below this time value will be given artificial hit times\n",
    "\n",
    "data = []\n",
    "\n",
    "numEvts = 50\n",
    "if len(events) < 20:\n",
    "    numEvts = len(x)\n",
    "    \n",
    "\n",
    "\n",
    "for i in events[0:numEvts]:\n",
    "    event_mask_1 = False\n",
    "    event_mask_2 = False\n",
    "    \n",
    "    event = {\n",
    "        \"infoText\": \"CALI BNL Prototype Event #\" + str(i),\n",
    "        \"colorScale\": {}\n",
    "    }\n",
    "    \n",
    "    mask = (event_ids == i)\n",
    "\n",
    "    # Filter out energies less than or equal to 0\n",
    "    valid_energies = [energy for energy in LG[mask] if energy > 300]\n",
    "\n",
    "    if valid_energies:\n",
    "        event_mask_1 = True\n",
    "        min_energy = min(valid_energies)\n",
    "        max_energy = max(valid_energies)\n",
    "\n",
    "        event[\"colorScale\"][\"min\"] = float(min_energy)\n",
    "        event[\"colorScale\"][\"max\"] = float(max_energy)\n",
    "\n",
    "        if use_log_scale:\n",
    "            # Logarithmic scaling\n",
    "            normalized_energy = [np.log(energy / min_energy) / np.log(max_energy / min_energy) if energy > 0 else energy for energy in LG[mask]]\n",
    "        else:\n",
    "            # Linear scaling\n",
    "            normalized_energy = [(energy - min_energy) / (max_energy - min_energy) if energy > 0 else energy for energy in LG[mask]]\n",
    "    else:\n",
    "        # If all energies are 0 or less, retain the original values\n",
    "        normalized_energy = LG[mask]\n",
    "\n",
    "    objects = []\n",
    "\n",
    "    for j in range(len(LG[mask])):\n",
    "        dist = np.sqrt((xpos[mask][j] / 200) ** 2 + (ypos[mask][j] / 200) ** 2 + (zpos[mask][j] / 200) ** 2)\n",
    "        c = 0.299792\n",
    "        time = dist / c\n",
    "        if normalized_energy[j] > 0:\n",
    "            event_mask_2 = True\n",
    "            obj = {\n",
    "                \"type\": \"hit\",\n",
    "                \"time\": float(time),\n",
    "                \"x\": float(xpos[mask][j] / 200),\n",
    "                \"y\": float(ypos[mask][j] / 200),\n",
    "                \"z\": float(zpos[mask][j] / 200),\n",
    "                \"color\": float(normalized_energy[j])\n",
    "            }\n",
    "\n",
    "            objects.append(obj)\n",
    "    if event_mask_1 & event_mask_2:\n",
    "        event[\"objects\"] = objects\n",
    "        data.append(event)\n",
    "\n",
    "eventPath = 'Events.json'\n",
    "# Write data to JSON file\n",
    "with open(eventPath, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "template_parameters = {\n",
    "    \"sides\": 4,\n",
    "    \"rmin1\": 0,\n",
    "    \"rmax1\": 1.386/2,\n",
    "    \"rmin2\": 0,\n",
    "    \"rmax2\": 1.386/2,\n",
    "    \"lengthOut\": 0.271526/2,\n",
    "    \"lengthIn\": 0.271526/2,\n",
    "    \"offsetIn\": 0,\n",
    "    \"angle\": 0,\n",
    "    \"R\": 0.5882352941176471,\n",
    "    \"G\": 0.5882352941176471,\n",
    "    \"B\": 1.0\n",
    "}\n",
    "\n",
    "# Extend the data for additional layers\n",
    "for i in range(1, 18): \n",
    "    new_entry = {\n",
    "        \"name\": f\"Layer{i}\",\n",
    "        \"parameters\": template_parameters.copy()  # Create a copy of the template parameters\n",
    "    }\n",
    "    new_entry[\"parameters\"][\"offset\"] = (0.1358/2) + (0.271526/2) * (i - 1)  # Update the offset\n",
    "    data.append(new_entry)\n",
    "\n",
    "\n",
    "# Write the updated data to a new JSON file\n",
    "with open('Detector.json', 'w') as file:\n",
    "    json.dump(data, file, indent=2)  # Save the updated data to a new JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
